{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in /venv/main/lib/python3.10/site-packages (1.6.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /venv/main/lib/python3.10/site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /venv/main/lib/python3.10/site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: numpy>=1.19.5 in /venv/main/lib/python3.10/site-packages (from scikit-learn) (2.1.2)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /venv/main/lib/python3.10/site-packages (from scikit-learn) (1.15.1)\n",
      "Collecting matplotlib\n",
      "  Downloading matplotlib-3.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.6/8.6 MB\u001b[0m \u001b[31m19.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "Collecting cycler>=0.10\n",
      "  Downloading cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Requirement already satisfied: numpy>=1.23 in /venv/main/lib/python3.10/site-packages (from matplotlib) (2.1.2)\n",
      "Collecting kiwisolver>=1.3.1\n",
      "  Downloading kiwisolver-1.4.8-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m37.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "Collecting pyparsing>=2.3.1\n",
      "  Downloading pyparsing-3.2.1-py3-none-any.whl (107 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m107.7/107.7 KB\u001b[0m \u001b[31m28.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil>=2.7 in /venv/main/lib/python3.10/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Collecting fonttools>=4.22.0\n",
      "  Downloading fonttools-4.56.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.6/4.6 MB\u001b[0m \u001b[31m49.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /venv/main/lib/python3.10/site-packages (from matplotlib) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in /venv/main/lib/python3.10/site-packages (from matplotlib) (11.0.0)\n",
      "Collecting contourpy>=1.0.1\n",
      "  Downloading contourpy-1.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (324 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m325.0/325.0 KB\u001b[0m \u001b[31m63.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "Requirement already satisfied: six>=1.5 in /venv/main/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "Installing collected packages: pyparsing, kiwisolver, fonttools, cycler, contourpy, matplotlib\n",
      "Successfully installed contourpy-1.3.1 cycler-0.12.1 fonttools-4.56.0 kiwisolver-1.4.8 matplotlib-3.10.0 pyparsing-3.2.1\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn\n",
    "!pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TUrjdTL_U0eo",
    "outputId": "61ae87c4-f83f-4cdf-bd65-a4f6c75ccaf4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f94b15d1050>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import time\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "from tqdm import tqdm\n",
    "\n",
    "# For reproducibility\n",
    "torch.manual_seed(42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SKOMXc64SB2K",
    "outputId": "9403998a-dc5e-40da-8fca-20d2f4805712"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Data augmentation and normalization for training\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.247, 0.243, 0.261))\n",
    "])\n",
    "\n",
    "# Only normalization for testing\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.247, 0.243, 0.261))\n",
    "])\n",
    "\n",
    "batch_size = 128\n",
    "\n",
    "train_dataset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\n",
    "test_dataset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "6D97bRF3SEBA"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class DepthwiseSeparableConv(nn.Module):\n",
    "    \"\"\"\n",
    "    Implements a depth-wise separable convolution: depthwise conv followed by pointwise conv.\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=3, stride=1, padding=1):\n",
    "        super(DepthwiseSeparableConv, self).__init__()\n",
    "        self.depthwise = nn.Conv2d(in_channels, in_channels, kernel_size=kernel_size, \n",
    "                                   stride=stride, padding=padding, groups=in_channels, bias=False)\n",
    "        self.pointwise = nn.Conv2d(in_channels, out_channels, kernel_size=1, bias=False)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.depthwise(x)\n",
    "        x = self.pointwise(x)\n",
    "        return x\n",
    "\n",
    "class DenseLayer(nn.Module):\n",
    "    \"\"\"\n",
    "    A single layer within a dense block.\n",
    "    If use_depthwise is True, uses a depth-wise separable conv; otherwise, a traditional conv.\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels, growth_rate, use_depthwise=True, drop_rate=0.0):\n",
    "        super(DenseLayer, self).__init__()\n",
    "        self.bn = nn.BatchNorm2d(in_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.use_depthwise = use_depthwise\n",
    "        if self.use_depthwise:\n",
    "            self.conv = DepthwiseSeparableConv(in_channels, growth_rate, kernel_size=3, stride=1, padding=1)\n",
    "        else:\n",
    "            self.conv = nn.Conv2d(in_channels, growth_rate, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.drop_rate = drop_rate\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv(self.relu(self.bn(x)))\n",
    "        if self.drop_rate > 0:\n",
    "            out = F.dropout(out, p=self.drop_rate, training=self.training)\n",
    "        return out\n",
    "\n",
    "class DenseBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    A dense block where each layer receives as input all previous layers’ outputs.\n",
    "    \"\"\"\n",
    "    def __init__(self, num_layers, in_channels, growth_rate, use_depthwise=True, drop_rate=0.0):\n",
    "        super(DenseBlock, self).__init__()\n",
    "        self.layers = nn.ModuleList()\n",
    "        for i in range(num_layers):\n",
    "            layer = DenseLayer(in_channels + i * growth_rate, growth_rate, use_depthwise, drop_rate)\n",
    "            self.layers.append(layer)\n",
    "\n",
    "    def forward(self, x):\n",
    "        features = [x]\n",
    "        for layer in self.layers:\n",
    "            new_feature = layer(torch.cat(features, 1))\n",
    "            features.append(new_feature)\n",
    "        return torch.cat(features, 1)\n",
    "\n",
    "class Transition(nn.Module):\n",
    "    \"\"\"\n",
    "    Transition layer used to down-sample the feature maps between dense blocks.\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels, out_channels, use_depthwise=True):\n",
    "        super(Transition, self).__init__()\n",
    "        self.bn = nn.BatchNorm2d(in_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        # 1x1 convolution (pointwise)\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=1, bias=False)\n",
    "        self.pool = nn.AvgPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(self.relu(self.bn(x)))\n",
    "        x = self.pool(x)\n",
    "        return x\n",
    "\n",
    "class DenseNetDS(nn.Module):\n",
    "    \"\"\"\n",
    "    DenseNet-inspired CNN with 4 dense blocks.\n",
    "    \n",
    "    Parameters:\n",
    "      - growth_rate: number of channels to add per DenseLayer.\n",
    "      - num_init_features: number of channels in the initial convolution.\n",
    "      - block_layers: list with the number of DenseLayers in each block.\n",
    "      - num_classes: number of output classes (10 for CIFAR-10).\n",
    "      - use_depthwise: if True, uses depth-wise separable convolutions.\n",
    "      - drop_rate: dropout rate.\n",
    "    \"\"\"\n",
    "    def __init__(self, growth_rate=12, num_init_features=32, block_layers=[4, 4, 4, 4],\n",
    "                 num_classes=10, use_depthwise=True, drop_rate=0.0):\n",
    "        super(DenseNetDS, self).__init__()\n",
    "        self.use_depthwise = use_depthwise\n",
    "        # Initial convolution layer\n",
    "        if self.use_depthwise:\n",
    "            self.conv0 = DepthwiseSeparableConv(3, num_init_features, kernel_size=3, stride=1, padding=1)\n",
    "        else:\n",
    "            self.conv0 = nn.Conv2d(3, num_init_features, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        \n",
    "        num_features = num_init_features\n",
    "        self.blocks = nn.ModuleList()\n",
    "        self.transitions = nn.ModuleList()\n",
    "\n",
    "        # Build dense blocks with transitions between them (except after the last block)\n",
    "        for i, num_layers in enumerate(block_layers):\n",
    "            block = DenseBlock(num_layers, num_features, growth_rate, use_depthwise, drop_rate)\n",
    "            self.blocks.append(block)\n",
    "            num_features = num_features + num_layers * growth_rate\n",
    "            if i != len(block_layers) - 1:\n",
    "                trans = Transition(num_features, num_features // 2, use_depthwise)\n",
    "                self.transitions.append(trans)\n",
    "                num_features = num_features // 2\n",
    "\n",
    "        # Final batch norm, global pooling, and fully connected layer\n",
    "        self.bn_final = nn.BatchNorm2d(num_features)\n",
    "        self.relu_final = nn.ReLU(inplace=True)\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(num_features, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv0(x)\n",
    "        for i, block in enumerate(self.blocks):\n",
    "            x = block(x)\n",
    "            if i < len(self.transitions):\n",
    "                x = self.transitions[i](x)\n",
    "        x = self.relu_final(self.bn_final(x))\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "wguRiK6TSGbU"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def train_one_epoch(model, device, train_loader, optimizer, criterion, epoch):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    loop = tqdm(train_loader, desc=f\"Epoch [{epoch}]\")\n",
    "    for inputs, targets in loop:\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += targets.size(0)\n",
    "        correct += predicted.eq(targets).sum().item()\n",
    "        loop.set_postfix(loss=loss.item(), acc=100.*correct/total)\n",
    "    \n",
    "    epoch_loss = running_loss / total\n",
    "    epoch_acc = 100. * correct / total\n",
    "    return epoch_loss, epoch_acc\n",
    "\n",
    "def evaluate_model(model, device, test_loader, criterion):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    all_targets = []\n",
    "    all_preds = []\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in test_loader:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "            all_targets.extend(targets.cpu().numpy())\n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "    avg_loss = running_loss / total\n",
    "    acc = 100. * correct / total\n",
    "    return avg_loss, acc, all_targets, all_preds\n",
    "\n",
    "def compute_metrics(targets, preds):\n",
    "    accuracy = accuracy_score(targets, preds)\n",
    "    precision = precision_score(targets, preds, average='macro', zero_division=0)\n",
    "    recall = recall_score(targets, preds, average='macro', zero_division=0)\n",
    "    f1 = f1_score(targets, preds, average='macro', zero_division=0)\n",
    "    report = classification_report(targets, preds, digits=4, zero_division=0)\n",
    "    return accuracy, precision, recall, f1, report\n",
    "\n",
    "def train_and_evaluate(model, device, train_loader, test_loader, criterion, optimizer, num_epochs, model_name=\"Model\"):\n",
    "    train_losses = []\n",
    "    train_accuracies = []\n",
    "    test_losses = []\n",
    "    test_accuracies = []\n",
    "    best_test_acc = 0.0\n",
    "    best_metrics = None\n",
    "    print(f\"\\nTraining {model_name} ...\")\n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        train_loss, train_acc = train_one_epoch(model, device, train_loader, optimizer, criterion, epoch)\n",
    "        test_loss, test_acc, targets, preds = evaluate_model(model, device, test_loader, criterion)\n",
    "        train_losses.append(train_loss)\n",
    "        train_accuracies.append(train_acc)\n",
    "        test_losses.append(test_loss)\n",
    "        test_accuracies.append(test_acc)\n",
    "        print(f\"{model_name} - Epoch {epoch}: Train Loss = {train_loss:.4f}, Train Acc = {train_acc:.2f}%, \"\n",
    "              f\"Test Loss = {test_loss:.4f}, Test Acc = {test_acc:.2f}%\")\n",
    "        if test_acc > best_test_acc:\n",
    "            best_test_acc = test_acc\n",
    "            best_metrics = (test_loss, test_acc, targets, preds)\n",
    "    return train_losses, train_accuracies, test_losses, test_accuracies, best_metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LFvo6qi1SJmV",
    "outputId": "e4b16ca1-5db1-4706-c856-ac0bffab1f6b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "\n",
      "Depth-wise Separable Convolution Model:\n",
      "Number of trainable parameters: 34613\n",
      "\n",
      "Training Depth-wise Model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [1]: 100%|██████████| 391/391 [00:08<00:00, 44.13it/s, acc=40.8, loss=1.14]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Depth-wise Model - Epoch 1: Train Loss = 1.6049, Train Acc = 40.78%, Test Loss = 1.2711, Test Acc = 53.06%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [2]: 100%|██████████| 391/391 [00:09<00:00, 43.18it/s, acc=58.1, loss=0.976]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Depth-wise Model - Epoch 2: Train Loss = 1.1627, Train Acc = 58.11%, Test Loss = 1.0443, Test Acc = 62.92%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [3]: 100%|██████████| 391/391 [00:09<00:00, 42.63it/s, acc=64.1, loss=1.11] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Depth-wise Model - Epoch 3: Train Loss = 0.9978, Train Acc = 64.07%, Test Loss = 0.9624, Test Acc = 66.04%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [4]: 100%|██████████| 391/391 [00:09<00:00, 41.78it/s, acc=67.6, loss=0.947]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Depth-wise Model - Epoch 4: Train Loss = 0.9033, Train Acc = 67.60%, Test Loss = 0.9168, Test Acc = 67.79%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [5]: 100%|██████████| 391/391 [00:08<00:00, 43.61it/s, acc=70.6, loss=0.98] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Depth-wise Model - Epoch 5: Train Loss = 0.8235, Train Acc = 70.62%, Test Loss = 0.8082, Test Acc = 71.57%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [6]: 100%|██████████| 391/391 [00:08<00:00, 43.79it/s, acc=73, loss=0.798]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Depth-wise Model - Epoch 6: Train Loss = 0.7656, Train Acc = 73.01%, Test Loss = 0.8037, Test Acc = 72.33%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [7]: 100%|██████████| 391/391 [00:08<00:00, 43.93it/s, acc=74.7, loss=0.718]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Depth-wise Model - Epoch 7: Train Loss = 0.7196, Train Acc = 74.67%, Test Loss = 0.7485, Test Acc = 73.84%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [8]: 100%|██████████| 391/391 [00:09<00:00, 42.71it/s, acc=76, loss=0.517]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Depth-wise Model - Epoch 8: Train Loss = 0.6807, Train Acc = 75.98%, Test Loss = 0.7143, Test Acc = 75.54%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [9]: 100%|██████████| 391/391 [00:09<00:00, 42.31it/s, acc=77.2, loss=0.765]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Depth-wise Model - Epoch 9: Train Loss = 0.6518, Train Acc = 77.25%, Test Loss = 0.6879, Test Acc = 76.26%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [10]: 100%|██████████| 391/391 [00:09<00:00, 43.23it/s, acc=78, loss=0.802]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Depth-wise Model - Epoch 10: Train Loss = 0.6260, Train Acc = 78.01%, Test Loss = 0.6628, Test Acc = 77.01%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [11]: 100%|██████████| 391/391 [00:09<00:00, 42.12it/s, acc=78.9, loss=0.669]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Depth-wise Model - Epoch 11: Train Loss = 0.6033, Train Acc = 78.93%, Test Loss = 0.6262, Test Acc = 78.56%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [12]: 100%|██████████| 391/391 [00:08<00:00, 44.50it/s, acc=79.5, loss=0.667]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Depth-wise Model - Epoch 12: Train Loss = 0.5887, Train Acc = 79.45%, Test Loss = 0.6545, Test Acc = 77.69%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [13]: 100%|██████████| 391/391 [00:09<00:00, 41.13it/s, acc=79.9, loss=0.572]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Depth-wise Model - Epoch 13: Train Loss = 0.5758, Train Acc = 79.88%, Test Loss = 0.6449, Test Acc = 78.45%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [14]: 100%|██████████| 391/391 [00:09<00:00, 43.07it/s, acc=80.5, loss=0.527]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Depth-wise Model - Epoch 14: Train Loss = 0.5567, Train Acc = 80.54%, Test Loss = 0.6375, Test Acc = 78.24%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [15]: 100%|██████████| 391/391 [00:09<00:00, 39.73it/s, acc=80.9, loss=0.498]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Depth-wise Model - Epoch 15: Train Loss = 0.5511, Train Acc = 80.90%, Test Loss = 0.5897, Test Acc = 79.82%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [16]: 100%|██████████| 391/391 [00:09<00:00, 39.46it/s, acc=81.3, loss=0.323]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Depth-wise Model - Epoch 16: Train Loss = 0.5350, Train Acc = 81.34%, Test Loss = 0.5708, Test Acc = 80.74%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [17]: 100%|██████████| 391/391 [00:09<00:00, 40.85it/s, acc=81.9, loss=0.56] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Depth-wise Model - Epoch 17: Train Loss = 0.5214, Train Acc = 81.88%, Test Loss = 0.5807, Test Acc = 80.33%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [18]: 100%|██████████| 391/391 [00:08<00:00, 44.20it/s, acc=82.2, loss=0.471]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Depth-wise Model - Epoch 18: Train Loss = 0.5128, Train Acc = 82.23%, Test Loss = 0.5714, Test Acc = 80.59%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [19]: 100%|██████████| 391/391 [00:09<00:00, 42.49it/s, acc=82.3, loss=0.5]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Depth-wise Model - Epoch 19: Train Loss = 0.5054, Train Acc = 82.33%, Test Loss = 0.5793, Test Acc = 80.35%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [20]: 100%|██████████| 391/391 [00:08<00:00, 45.80it/s, acc=82.7, loss=0.589]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Depth-wise Model - Epoch 20: Train Loss = 0.4967, Train Acc = 82.70%, Test Loss = 0.5534, Test Acc = 80.78%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [21]: 100%|██████████| 391/391 [00:08<00:00, 43.51it/s, acc=82.8, loss=0.616]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Depth-wise Model - Epoch 21: Train Loss = 0.4925, Train Acc = 82.78%, Test Loss = 0.5672, Test Acc = 80.61%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [22]: 100%|██████████| 391/391 [00:09<00:00, 42.37it/s, acc=83.1, loss=0.425]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Depth-wise Model - Epoch 22: Train Loss = 0.4824, Train Acc = 83.13%, Test Loss = 0.5515, Test Acc = 81.17%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [23]: 100%|██████████| 391/391 [00:08<00:00, 44.45it/s, acc=83.4, loss=0.431]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Depth-wise Model - Epoch 23: Train Loss = 0.4764, Train Acc = 83.35%, Test Loss = 0.5651, Test Acc = 81.01%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [24]: 100%|██████████| 391/391 [00:08<00:00, 44.03it/s, acc=83.5, loss=0.474]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Depth-wise Model - Epoch 24: Train Loss = 0.4727, Train Acc = 83.50%, Test Loss = 0.5739, Test Acc = 80.22%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [25]: 100%|██████████| 391/391 [00:09<00:00, 41.72it/s, acc=84, loss=0.396]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Depth-wise Model - Epoch 25: Train Loss = 0.4609, Train Acc = 83.98%, Test Loss = 0.5275, Test Acc = 81.95%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [26]: 100%|██████████| 391/391 [00:09<00:00, 43.38it/s, acc=84.2, loss=0.461]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Depth-wise Model - Epoch 26: Train Loss = 0.4532, Train Acc = 84.19%, Test Loss = 0.5339, Test Acc = 81.42%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [27]: 100%|██████████| 391/391 [00:09<00:00, 42.52it/s, acc=84.2, loss=0.41] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Depth-wise Model - Epoch 27: Train Loss = 0.4547, Train Acc = 84.18%, Test Loss = 0.5289, Test Acc = 82.09%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [28]: 100%|██████████| 391/391 [00:09<00:00, 41.28it/s, acc=84.4, loss=0.41] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Depth-wise Model - Epoch 28: Train Loss = 0.4459, Train Acc = 84.35%, Test Loss = 0.5198, Test Acc = 82.51%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [29]: 100%|██████████| 391/391 [00:08<00:00, 43.60it/s, acc=84.5, loss=0.487]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Depth-wise Model - Epoch 29: Train Loss = 0.4402, Train Acc = 84.54%, Test Loss = 0.5456, Test Acc = 82.02%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [30]: 100%|██████████| 391/391 [00:09<00:00, 43.33it/s, acc=84.5, loss=0.653]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Depth-wise Model - Epoch 30: Train Loss = 0.4382, Train Acc = 84.53%, Test Loss = 0.5228, Test Acc = 82.30%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [31]: 100%|██████████| 391/391 [00:09<00:00, 42.20it/s, acc=84.7, loss=0.62] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Depth-wise Model - Epoch 31: Train Loss = 0.4348, Train Acc = 84.72%, Test Loss = 0.4905, Test Acc = 83.34%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [32]: 100%|██████████| 391/391 [00:09<00:00, 42.36it/s, acc=85.1, loss=0.356]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Depth-wise Model - Epoch 32: Train Loss = 0.4265, Train Acc = 85.14%, Test Loss = 0.4958, Test Acc = 83.30%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [33]: 100%|██████████| 391/391 [00:08<00:00, 46.12it/s, acc=85.2, loss=0.591]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Depth-wise Model - Epoch 33: Train Loss = 0.4255, Train Acc = 85.21%, Test Loss = 0.5152, Test Acc = 82.78%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [34]: 100%|██████████| 391/391 [00:08<00:00, 45.85it/s, acc=85.3, loss=0.415]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Depth-wise Model - Epoch 34: Train Loss = 0.4168, Train Acc = 85.28%, Test Loss = 0.5559, Test Acc = 82.20%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [35]: 100%|██████████| 391/391 [00:08<00:00, 47.09it/s, acc=85.2, loss=0.432]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Depth-wise Model - Epoch 35: Train Loss = 0.4201, Train Acc = 85.16%, Test Loss = 0.5382, Test Acc = 82.22%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [36]: 100%|██████████| 391/391 [00:08<00:00, 43.48it/s, acc=85.5, loss=0.417]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Depth-wise Model - Epoch 36: Train Loss = 0.4150, Train Acc = 85.49%, Test Loss = 0.4926, Test Acc = 83.40%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [37]: 100%|██████████| 391/391 [00:09<00:00, 43.28it/s, acc=86.1, loss=0.501]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Depth-wise Model - Epoch 37: Train Loss = 0.4014, Train Acc = 86.06%, Test Loss = 0.4845, Test Acc = 83.71%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [38]: 100%|██████████| 391/391 [00:08<00:00, 44.00it/s, acc=85.9, loss=0.382]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Depth-wise Model - Epoch 38: Train Loss = 0.4071, Train Acc = 85.87%, Test Loss = 0.4960, Test Acc = 83.44%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [39]: 100%|██████████| 391/391 [00:08<00:00, 44.13it/s, acc=85.8, loss=0.563]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Depth-wise Model - Epoch 39: Train Loss = 0.4022, Train Acc = 85.81%, Test Loss = 0.5050, Test Acc = 83.37%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [40]: 100%|██████████| 391/391 [00:08<00:00, 43.91it/s, acc=85.9, loss=0.387]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Depth-wise Model - Epoch 40: Train Loss = 0.4010, Train Acc = 85.89%, Test Loss = 0.4961, Test Acc = 83.64%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [41]: 100%|██████████| 391/391 [00:08<00:00, 43.56it/s, acc=86.2, loss=0.32] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Depth-wise Model - Epoch 41: Train Loss = 0.3942, Train Acc = 86.16%, Test Loss = 0.4801, Test Acc = 84.15%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [42]: 100%|██████████| 391/391 [00:09<00:00, 42.94it/s, acc=86.2, loss=0.608]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Depth-wise Model - Epoch 42: Train Loss = 0.3956, Train Acc = 86.15%, Test Loss = 0.5014, Test Acc = 83.25%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [43]: 100%|██████████| 391/391 [00:09<00:00, 41.58it/s, acc=86.3, loss=0.346]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Depth-wise Model - Epoch 43: Train Loss = 0.3883, Train Acc = 86.34%, Test Loss = 0.4768, Test Acc = 83.91%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [44]: 100%|██████████| 391/391 [00:08<00:00, 43.94it/s, acc=86.6, loss=0.376]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Depth-wise Model - Epoch 44: Train Loss = 0.3815, Train Acc = 86.63%, Test Loss = 0.5203, Test Acc = 82.79%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [45]: 100%|██████████| 391/391 [00:08<00:00, 44.30it/s, acc=86.5, loss=0.602]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Depth-wise Model - Epoch 45: Train Loss = 0.3869, Train Acc = 86.51%, Test Loss = 0.4959, Test Acc = 83.47%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [46]: 100%|██████████| 391/391 [00:08<00:00, 46.63it/s, acc=86.5, loss=0.329]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Depth-wise Model - Epoch 46: Train Loss = 0.3809, Train Acc = 86.48%, Test Loss = 0.4898, Test Acc = 83.59%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [47]: 100%|██████████| 391/391 [00:08<00:00, 43.96it/s, acc=86.9, loss=0.335]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Depth-wise Model - Epoch 47: Train Loss = 0.3745, Train Acc = 86.93%, Test Loss = 0.4841, Test Acc = 84.42%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [48]: 100%|██████████| 391/391 [00:09<00:00, 41.73it/s, acc=86.9, loss=0.279]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Depth-wise Model - Epoch 48: Train Loss = 0.3780, Train Acc = 86.90%, Test Loss = 0.5079, Test Acc = 82.83%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [49]: 100%|██████████| 391/391 [00:09<00:00, 43.32it/s, acc=86.8, loss=0.339]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Depth-wise Model - Epoch 49: Train Loss = 0.3731, Train Acc = 86.82%, Test Loss = 0.4827, Test Acc = 83.98%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [50]: 100%|██████████| 391/391 [00:08<00:00, 45.98it/s, acc=87, loss=0.661]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Depth-wise Model - Epoch 50: Train Loss = 0.3698, Train Acc = 86.97%, Test Loss = 0.4855, Test Acc = 84.33%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [51]: 100%|██████████| 391/391 [00:08<00:00, 45.37it/s, acc=86.9, loss=0.485]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Depth-wise Model - Epoch 51: Train Loss = 0.3698, Train Acc = 86.90%, Test Loss = 0.4881, Test Acc = 84.06%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [52]: 100%|██████████| 391/391 [00:08<00:00, 43.74it/s, acc=87.1, loss=0.359]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Depth-wise Model - Epoch 52: Train Loss = 0.3664, Train Acc = 87.14%, Test Loss = 0.4589, Test Acc = 84.64%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [53]: 100%|██████████| 391/391 [00:08<00:00, 45.78it/s, acc=87.2, loss=0.37] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Depth-wise Model - Epoch 53: Train Loss = 0.3648, Train Acc = 87.16%, Test Loss = 0.4864, Test Acc = 84.29%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [54]: 100%|██████████| 391/391 [00:08<00:00, 43.60it/s, acc=87, loss=0.367]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Depth-wise Model - Epoch 54: Train Loss = 0.3663, Train Acc = 86.96%, Test Loss = 0.4703, Test Acc = 84.59%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [55]: 100%|██████████| 391/391 [00:08<00:00, 43.75it/s, acc=87.4, loss=0.452]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Depth-wise Model - Epoch 55: Train Loss = 0.3571, Train Acc = 87.44%, Test Loss = 0.4835, Test Acc = 84.59%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [56]: 100%|██████████| 391/391 [00:08<00:00, 43.87it/s, acc=87.3, loss=0.299]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Depth-wise Model - Epoch 56: Train Loss = 0.3617, Train Acc = 87.33%, Test Loss = 0.4998, Test Acc = 83.68%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [57]: 100%|██████████| 391/391 [00:09<00:00, 43.42it/s, acc=87.4, loss=0.607]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Depth-wise Model - Epoch 57: Train Loss = 0.3589, Train Acc = 87.38%, Test Loss = 0.5326, Test Acc = 83.03%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [58]: 100%|██████████| 391/391 [00:08<00:00, 43.57it/s, acc=87.7, loss=0.373]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Depth-wise Model - Epoch 58: Train Loss = 0.3533, Train Acc = 87.65%, Test Loss = 0.4834, Test Acc = 84.06%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [59]: 100%|██████████| 391/391 [00:08<00:00, 46.81it/s, acc=87.4, loss=0.449]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Depth-wise Model - Epoch 59: Train Loss = 0.3529, Train Acc = 87.44%, Test Loss = 0.4772, Test Acc = 84.35%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [60]: 100%|██████████| 391/391 [00:08<00:00, 44.27it/s, acc=87.7, loss=0.32] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Depth-wise Model - Epoch 60: Train Loss = 0.3467, Train Acc = 87.73%, Test Loss = 0.4714, Test Acc = 84.82%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [61]: 100%|██████████| 391/391 [00:08<00:00, 45.37it/s, acc=87.7, loss=0.445]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Depth-wise Model - Epoch 61: Train Loss = 0.3504, Train Acc = 87.74%, Test Loss = 0.4621, Test Acc = 85.15%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [62]: 100%|██████████| 391/391 [00:08<00:00, 45.45it/s, acc=87.7, loss=0.269]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Depth-wise Model - Epoch 62: Train Loss = 0.3479, Train Acc = 87.67%, Test Loss = 0.5066, Test Acc = 83.65%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [63]: 100%|██████████| 391/391 [00:09<00:00, 43.23it/s, acc=88, loss=0.483]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Depth-wise Model - Epoch 63: Train Loss = 0.3412, Train Acc = 87.99%, Test Loss = 0.4644, Test Acc = 84.58%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [64]: 100%|██████████| 391/391 [00:08<00:00, 43.90it/s, acc=88.1, loss=0.298]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Depth-wise Model - Epoch 64: Train Loss = 0.3409, Train Acc = 88.05%, Test Loss = 0.4784, Test Acc = 84.37%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [65]: 100%|██████████| 391/391 [00:08<00:00, 43.88it/s, acc=88, loss=0.279]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Depth-wise Model - Epoch 65: Train Loss = 0.3403, Train Acc = 87.96%, Test Loss = 0.4699, Test Acc = 84.68%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [66]: 100%|██████████| 391/391 [00:08<00:00, 44.35it/s, acc=88, loss=0.493]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Depth-wise Model - Epoch 66: Train Loss = 0.3406, Train Acc = 87.99%, Test Loss = 0.4604, Test Acc = 84.81%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [67]: 100%|██████████| 391/391 [00:08<00:00, 43.76it/s, acc=88.1, loss=0.36] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Depth-wise Model - Epoch 67: Train Loss = 0.3393, Train Acc = 88.09%, Test Loss = 0.4815, Test Acc = 84.38%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [68]: 100%|██████████| 391/391 [00:08<00:00, 45.74it/s, acc=88.2, loss=0.252]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Depth-wise Model - Epoch 68: Train Loss = 0.3307, Train Acc = 88.21%, Test Loss = 0.4750, Test Acc = 84.73%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [69]: 100%|██████████| 391/391 [00:08<00:00, 43.76it/s, acc=88.1, loss=0.284]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Depth-wise Model - Epoch 69: Train Loss = 0.3394, Train Acc = 88.11%, Test Loss = 0.4704, Test Acc = 84.75%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [70]: 100%|██████████| 391/391 [00:08<00:00, 44.40it/s, acc=88.2, loss=0.471]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Depth-wise Model - Epoch 70: Train Loss = 0.3343, Train Acc = 88.21%, Test Loss = 0.4758, Test Acc = 84.54%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [71]: 100%|██████████| 391/391 [00:09<00:00, 42.48it/s, acc=88.2, loss=0.323]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Depth-wise Model - Epoch 71: Train Loss = 0.3299, Train Acc = 88.21%, Test Loss = 0.4805, Test Acc = 84.32%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [72]: 100%|██████████| 391/391 [00:09<00:00, 43.16it/s, acc=88.3, loss=0.369]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Depth-wise Model - Epoch 72: Train Loss = 0.3310, Train Acc = 88.34%, Test Loss = 0.4560, Test Acc = 85.91%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [73]: 100%|██████████| 391/391 [00:09<00:00, 42.82it/s, acc=88.5, loss=0.233]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Depth-wise Model - Epoch 73: Train Loss = 0.3239, Train Acc = 88.52%, Test Loss = 0.4704, Test Acc = 85.16%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [74]: 100%|██████████| 391/391 [00:09<00:00, 43.12it/s, acc=88.5, loss=0.282]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Depth-wise Model - Epoch 74: Train Loss = 0.3264, Train Acc = 88.50%, Test Loss = 0.4765, Test Acc = 84.84%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [75]: 100%|██████████| 391/391 [00:08<00:00, 44.09it/s, acc=88.5, loss=0.422]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Depth-wise Model - Epoch 75: Train Loss = 0.3248, Train Acc = 88.46%, Test Loss = 0.4837, Test Acc = 84.93%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [76]: 100%|██████████| 391/391 [00:08<00:00, 45.00it/s, acc=88.7, loss=0.348]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Depth-wise Model - Epoch 76: Train Loss = 0.3209, Train Acc = 88.73%, Test Loss = 0.4724, Test Acc = 85.31%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [77]: 100%|██████████| 391/391 [00:08<00:00, 43.56it/s, acc=88.5, loss=0.395]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Depth-wise Model - Epoch 77: Train Loss = 0.3281, Train Acc = 88.50%, Test Loss = 0.4521, Test Acc = 85.42%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [78]: 100%|██████████| 391/391 [00:08<00:00, 44.95it/s, acc=88.8, loss=0.306]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Depth-wise Model - Epoch 78: Train Loss = 0.3203, Train Acc = 88.79%, Test Loss = 0.4876, Test Acc = 85.01%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [79]: 100%|██████████| 391/391 [00:08<00:00, 44.44it/s, acc=88.7, loss=0.359]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Depth-wise Model - Epoch 79: Train Loss = 0.3222, Train Acc = 88.72%, Test Loss = 0.4707, Test Acc = 85.02%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [80]: 100%|██████████| 391/391 [00:09<00:00, 42.53it/s, acc=89, loss=0.236]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Depth-wise Model - Epoch 80: Train Loss = 0.3153, Train Acc = 89.03%, Test Loss = 0.4669, Test Acc = 85.06%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [81]: 100%|██████████| 391/391 [00:09<00:00, 42.80it/s, acc=88.8, loss=0.337]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Depth-wise Model - Epoch 81: Train Loss = 0.3156, Train Acc = 88.80%, Test Loss = 0.4851, Test Acc = 84.52%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [82]: 100%|██████████| 391/391 [00:09<00:00, 43.44it/s, acc=88.8, loss=0.225]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Depth-wise Model - Epoch 82: Train Loss = 0.3167, Train Acc = 88.82%, Test Loss = 0.4753, Test Acc = 84.95%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [83]: 100%|██████████| 391/391 [00:08<00:00, 44.27it/s, acc=88.9, loss=0.392]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Depth-wise Model - Epoch 83: Train Loss = 0.3181, Train Acc = 88.87%, Test Loss = 0.5113, Test Acc = 83.72%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [84]: 100%|██████████| 391/391 [00:09<00:00, 43.35it/s, acc=88.8, loss=0.454]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Depth-wise Model - Epoch 84: Train Loss = 0.3175, Train Acc = 88.75%, Test Loss = 0.4494, Test Acc = 85.65%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [85]: 100%|██████████| 391/391 [00:08<00:00, 44.40it/s, acc=88.8, loss=0.259]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Depth-wise Model - Epoch 85: Train Loss = 0.3114, Train Acc = 88.84%, Test Loss = 0.4945, Test Acc = 84.81%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [86]: 100%|██████████| 391/391 [00:09<00:00, 42.47it/s, acc=89.3, loss=0.319]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Depth-wise Model - Epoch 86: Train Loss = 0.3091, Train Acc = 89.25%, Test Loss = 0.4550, Test Acc = 85.49%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [87]: 100%|██████████| 391/391 [00:09<00:00, 42.92it/s, acc=89, loss=0.221]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Depth-wise Model - Epoch 87: Train Loss = 0.3116, Train Acc = 88.98%, Test Loss = 0.4515, Test Acc = 85.67%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [88]: 100%|██████████| 391/391 [00:08<00:00, 43.59it/s, acc=89.1, loss=0.24] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Depth-wise Model - Epoch 88: Train Loss = 0.3089, Train Acc = 89.15%, Test Loss = 0.4568, Test Acc = 85.29%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [89]: 100%|██████████| 391/391 [00:09<00:00, 42.34it/s, acc=89, loss=0.322]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Depth-wise Model - Epoch 89: Train Loss = 0.3093, Train Acc = 89.01%, Test Loss = 0.4917, Test Acc = 84.78%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [90]: 100%|██████████| 391/391 [00:08<00:00, 43.79it/s, acc=89.3, loss=0.407]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Depth-wise Model - Epoch 90: Train Loss = 0.3077, Train Acc = 89.26%, Test Loss = 0.4571, Test Acc = 85.54%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [91]: 100%|██████████| 391/391 [00:08<00:00, 46.33it/s, acc=89.4, loss=0.18] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Depth-wise Model - Epoch 91: Train Loss = 0.3039, Train Acc = 89.37%, Test Loss = 0.4408, Test Acc = 85.89%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [92]: 100%|██████████| 391/391 [00:09<00:00, 43.00it/s, acc=89.2, loss=0.243]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Depth-wise Model - Epoch 92: Train Loss = 0.3077, Train Acc = 89.23%, Test Loss = 0.4504, Test Acc = 85.65%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [93]: 100%|██████████| 391/391 [00:08<00:00, 44.15it/s, acc=89.3, loss=0.265]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Depth-wise Model - Epoch 93: Train Loss = 0.3046, Train Acc = 89.30%, Test Loss = 0.4704, Test Acc = 85.36%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [94]: 100%|██████████| 391/391 [00:08<00:00, 44.41it/s, acc=89.2, loss=0.319]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Depth-wise Model - Epoch 94: Train Loss = 0.3031, Train Acc = 89.18%, Test Loss = 0.4510, Test Acc = 85.78%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [95]: 100%|██████████| 391/391 [00:08<00:00, 43.84it/s, acc=89.3, loss=0.311]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Depth-wise Model - Epoch 95: Train Loss = 0.3018, Train Acc = 89.26%, Test Loss = 0.4405, Test Acc = 85.98%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [96]: 100%|██████████| 391/391 [00:08<00:00, 43.90it/s, acc=89.3, loss=0.201]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Depth-wise Model - Epoch 96: Train Loss = 0.3028, Train Acc = 89.32%, Test Loss = 0.4675, Test Acc = 85.52%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [97]: 100%|██████████| 391/391 [00:09<00:00, 43.22it/s, acc=89.4, loss=0.348]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Depth-wise Model - Epoch 97: Train Loss = 0.2990, Train Acc = 89.43%, Test Loss = 0.4773, Test Acc = 85.22%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [98]: 100%|██████████| 391/391 [00:09<00:00, 42.94it/s, acc=89.2, loss=0.348]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Depth-wise Model - Epoch 98: Train Loss = 0.3014, Train Acc = 89.23%, Test Loss = 0.5123, Test Acc = 84.12%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [99]: 100%|██████████| 391/391 [00:08<00:00, 43.61it/s, acc=89.5, loss=0.259]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Depth-wise Model - Epoch 99: Train Loss = 0.2965, Train Acc = 89.47%, Test Loss = 0.4842, Test Acc = 84.88%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [100]: 100%|██████████| 391/391 [00:08<00:00, 43.50it/s, acc=89.5, loss=0.333]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Depth-wise Model - Epoch 100: Train Loss = 0.2963, Train Acc = 89.51%, Test Loss = 0.4393, Test Acc = 85.83%\n",
      "\n",
      "Traditional Convolution Model:\n",
      "Number of trainable parameters: 116786\n",
      "\n",
      "Training Traditional Model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [1]: 100%|██████████| 391/391 [00:08<00:00, 46.67it/s, acc=48.3, loss=1.06] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traditional Model - Epoch 1: Train Loss = 1.4232, Train Acc = 48.27%, Test Loss = 1.2017, Test Acc = 57.19%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [2]: 100%|██████████| 391/391 [00:08<00:00, 46.20it/s, acc=64.6, loss=0.963]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traditional Model - Epoch 2: Train Loss = 0.9926, Train Acc = 64.59%, Test Loss = 1.1969, Test Acc = 59.13%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [3]: 100%|██████████| 391/391 [00:08<00:00, 46.57it/s, acc=70.4, loss=0.687]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traditional Model - Epoch 3: Train Loss = 0.8365, Train Acc = 70.38%, Test Loss = 0.9666, Test Acc = 67.31%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [4]: 100%|██████████| 391/391 [00:08<00:00, 47.00it/s, acc=74.2, loss=0.625]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traditional Model - Epoch 4: Train Loss = 0.7358, Train Acc = 74.18%, Test Loss = 0.7440, Test Acc = 73.74%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [5]: 100%|██████████| 391/391 [00:08<00:00, 47.24it/s, acc=76.5, loss=0.701]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traditional Model - Epoch 5: Train Loss = 0.6721, Train Acc = 76.52%, Test Loss = 0.6856, Test Acc = 76.44%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [6]: 100%|██████████| 391/391 [00:08<00:00, 48.02it/s, acc=78.4, loss=0.537]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traditional Model - Epoch 6: Train Loss = 0.6186, Train Acc = 78.43%, Test Loss = 0.7565, Test Acc = 73.58%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [7]: 100%|██████████| 391/391 [00:08<00:00, 47.50it/s, acc=79.7, loss=0.639]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traditional Model - Epoch 7: Train Loss = 0.5848, Train Acc = 79.75%, Test Loss = 0.6788, Test Acc = 76.81%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [8]: 100%|██████████| 391/391 [00:08<00:00, 47.89it/s, acc=80.8, loss=0.591]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traditional Model - Epoch 8: Train Loss = 0.5558, Train Acc = 80.80%, Test Loss = 0.6140, Test Acc = 78.88%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [9]: 100%|██████████| 391/391 [00:08<00:00, 47.27it/s, acc=81.9, loss=0.485]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traditional Model - Epoch 9: Train Loss = 0.5253, Train Acc = 81.93%, Test Loss = 0.6269, Test Acc = 78.82%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [10]: 100%|██████████| 391/391 [00:08<00:00, 47.73it/s, acc=82.5, loss=0.275]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traditional Model - Epoch 10: Train Loss = 0.5049, Train Acc = 82.48%, Test Loss = 0.6586, Test Acc = 77.94%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [11]: 100%|██████████| 391/391 [00:08<00:00, 47.91it/s, acc=83.1, loss=0.504]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traditional Model - Epoch 11: Train Loss = 0.4895, Train Acc = 83.15%, Test Loss = 0.5539, Test Acc = 81.83%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [12]: 100%|██████████| 391/391 [00:08<00:00, 47.85it/s, acc=84, loss=0.504]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traditional Model - Epoch 12: Train Loss = 0.4670, Train Acc = 83.98%, Test Loss = 0.5325, Test Acc = 82.07%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [13]: 100%|██████████| 391/391 [00:08<00:00, 47.26it/s, acc=84.3, loss=0.481]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traditional Model - Epoch 13: Train Loss = 0.4532, Train Acc = 84.28%, Test Loss = 0.5436, Test Acc = 81.76%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [14]: 100%|██████████| 391/391 [00:08<00:00, 47.21it/s, acc=84.8, loss=0.575]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traditional Model - Epoch 14: Train Loss = 0.4346, Train Acc = 84.83%, Test Loss = 0.5321, Test Acc = 82.10%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [15]: 100%|██████████| 391/391 [00:08<00:00, 47.24it/s, acc=85.3, loss=0.398]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traditional Model - Epoch 15: Train Loss = 0.4230, Train Acc = 85.32%, Test Loss = 0.5629, Test Acc = 80.98%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [16]: 100%|██████████| 391/391 [00:08<00:00, 47.47it/s, acc=85.6, loss=0.509]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traditional Model - Epoch 16: Train Loss = 0.4165, Train Acc = 85.57%, Test Loss = 0.5573, Test Acc = 82.04%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [17]: 100%|██████████| 391/391 [00:07<00:00, 49.06it/s, acc=85.9, loss=0.454]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traditional Model - Epoch 17: Train Loss = 0.4060, Train Acc = 85.92%, Test Loss = 0.4960, Test Acc = 83.38%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [18]: 100%|██████████| 391/391 [00:08<00:00, 47.70it/s, acc=86.7, loss=0.43] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traditional Model - Epoch 18: Train Loss = 0.3846, Train Acc = 86.69%, Test Loss = 0.5142, Test Acc = 83.65%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [19]: 100%|██████████| 391/391 [00:08<00:00, 47.78it/s, acc=86.6, loss=0.507]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traditional Model - Epoch 19: Train Loss = 0.3853, Train Acc = 86.59%, Test Loss = 0.4620, Test Acc = 84.43%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [20]: 100%|██████████| 391/391 [00:08<00:00, 47.76it/s, acc=86.9, loss=0.364]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traditional Model - Epoch 20: Train Loss = 0.3728, Train Acc = 86.93%, Test Loss = 0.4685, Test Acc = 84.36%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [21]: 100%|██████████| 391/391 [00:08<00:00, 47.30it/s, acc=87.2, loss=0.387]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traditional Model - Epoch 21: Train Loss = 0.3678, Train Acc = 87.19%, Test Loss = 0.4522, Test Acc = 85.28%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [22]: 100%|██████████| 391/391 [00:08<00:00, 47.64it/s, acc=87.5, loss=0.339]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traditional Model - Epoch 22: Train Loss = 0.3587, Train Acc = 87.50%, Test Loss = 0.4941, Test Acc = 84.44%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [23]: 100%|██████████| 391/391 [00:08<00:00, 46.54it/s, acc=87.7, loss=0.389]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traditional Model - Epoch 23: Train Loss = 0.3527, Train Acc = 87.68%, Test Loss = 0.4708, Test Acc = 85.14%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [24]: 100%|██████████| 391/391 [00:08<00:00, 47.32it/s, acc=87.8, loss=0.212]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traditional Model - Epoch 24: Train Loss = 0.3456, Train Acc = 87.81%, Test Loss = 0.4653, Test Acc = 84.95%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [25]: 100%|██████████| 391/391 [00:08<00:00, 46.77it/s, acc=88, loss=0.375]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traditional Model - Epoch 25: Train Loss = 0.3424, Train Acc = 88.02%, Test Loss = 0.4502, Test Acc = 85.10%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [26]: 100%|██████████| 391/391 [00:08<00:00, 47.82it/s, acc=88.4, loss=0.35] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traditional Model - Epoch 26: Train Loss = 0.3335, Train Acc = 88.41%, Test Loss = 0.4462, Test Acc = 85.68%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [27]: 100%|██████████| 391/391 [00:08<00:00, 46.97it/s, acc=88.6, loss=0.16] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traditional Model - Epoch 27: Train Loss = 0.3289, Train Acc = 88.58%, Test Loss = 0.4494, Test Acc = 85.42%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [28]: 100%|██████████| 391/391 [00:08<00:00, 47.13it/s, acc=88.8, loss=0.408]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traditional Model - Epoch 28: Train Loss = 0.3212, Train Acc = 88.75%, Test Loss = 0.4778, Test Acc = 84.77%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [29]: 100%|██████████| 391/391 [00:08<00:00, 47.63it/s, acc=88.7, loss=0.289]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traditional Model - Epoch 29: Train Loss = 0.3223, Train Acc = 88.74%, Test Loss = 0.4332, Test Acc = 85.98%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [30]: 100%|██████████| 391/391 [00:08<00:00, 47.72it/s, acc=89.1, loss=0.413]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traditional Model - Epoch 30: Train Loss = 0.3115, Train Acc = 89.05%, Test Loss = 0.4409, Test Acc = 85.93%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [31]: 100%|██████████| 391/391 [00:08<00:00, 47.52it/s, acc=89.1, loss=0.337]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traditional Model - Epoch 31: Train Loss = 0.3141, Train Acc = 89.06%, Test Loss = 0.4293, Test Acc = 86.19%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [32]: 100%|██████████| 391/391 [00:08<00:00, 47.45it/s, acc=89.3, loss=0.176]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traditional Model - Epoch 32: Train Loss = 0.3031, Train Acc = 89.32%, Test Loss = 0.4246, Test Acc = 86.25%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [33]: 100%|██████████| 391/391 [00:08<00:00, 46.95it/s, acc=89.6, loss=0.345]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traditional Model - Epoch 33: Train Loss = 0.2973, Train Acc = 89.63%, Test Loss = 0.4697, Test Acc = 85.37%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [34]: 100%|██████████| 391/391 [00:08<00:00, 47.93it/s, acc=89.7, loss=0.243]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traditional Model - Epoch 34: Train Loss = 0.2955, Train Acc = 89.66%, Test Loss = 0.5127, Test Acc = 83.90%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [35]: 100%|██████████| 391/391 [00:08<00:00, 47.32it/s, acc=89.8, loss=0.289]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traditional Model - Epoch 35: Train Loss = 0.2918, Train Acc = 89.76%, Test Loss = 0.4344, Test Acc = 86.04%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [36]: 100%|██████████| 391/391 [00:08<00:00, 47.49it/s, acc=90, loss=0.259]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traditional Model - Epoch 36: Train Loss = 0.2835, Train Acc = 90.05%, Test Loss = 0.4250, Test Acc = 86.67%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [37]: 100%|██████████| 391/391 [00:08<00:00, 47.43it/s, acc=90.1, loss=0.474]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traditional Model - Epoch 37: Train Loss = 0.2818, Train Acc = 90.14%, Test Loss = 0.4671, Test Acc = 85.06%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [38]: 100%|██████████| 391/391 [00:08<00:00, 47.35it/s, acc=90.3, loss=0.218]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traditional Model - Epoch 38: Train Loss = 0.2769, Train Acc = 90.31%, Test Loss = 0.4675, Test Acc = 85.52%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [39]: 100%|██████████| 391/391 [00:08<00:00, 47.88it/s, acc=90.5, loss=0.189]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traditional Model - Epoch 39: Train Loss = 0.2707, Train Acc = 90.49%, Test Loss = 0.4375, Test Acc = 86.41%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [40]: 100%|██████████| 391/391 [00:08<00:00, 48.14it/s, acc=90.5, loss=0.429]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traditional Model - Epoch 40: Train Loss = 0.2714, Train Acc = 90.52%, Test Loss = 0.4133, Test Acc = 87.14%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [41]: 100%|██████████| 391/391 [00:08<00:00, 47.45it/s, acc=90.6, loss=0.212]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traditional Model - Epoch 41: Train Loss = 0.2657, Train Acc = 90.56%, Test Loss = 0.4268, Test Acc = 86.77%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [42]: 100%|██████████| 391/391 [00:08<00:00, 47.76it/s, acc=90.8, loss=0.246]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traditional Model - Epoch 42: Train Loss = 0.2596, Train Acc = 90.79%, Test Loss = 0.4149, Test Acc = 87.09%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [43]: 100%|██████████| 391/391 [00:08<00:00, 47.29it/s, acc=90.8, loss=0.265]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traditional Model - Epoch 43: Train Loss = 0.2585, Train Acc = 90.85%, Test Loss = 0.4542, Test Acc = 86.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [44]: 100%|██████████| 391/391 [00:08<00:00, 46.76it/s, acc=91.1, loss=0.249]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traditional Model - Epoch 44: Train Loss = 0.2570, Train Acc = 91.06%, Test Loss = 0.4088, Test Acc = 87.17%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [45]: 100%|██████████| 391/391 [00:08<00:00, 46.83it/s, acc=91.1, loss=0.174] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traditional Model - Epoch 45: Train Loss = 0.2521, Train Acc = 91.13%, Test Loss = 0.4501, Test Acc = 86.33%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [46]: 100%|██████████| 391/391 [00:08<00:00, 47.48it/s, acc=90.9, loss=0.364]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traditional Model - Epoch 46: Train Loss = 0.2523, Train Acc = 90.94%, Test Loss = 0.4210, Test Acc = 87.08%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [47]: 100%|██████████| 391/391 [00:08<00:00, 47.42it/s, acc=91.4, loss=0.248] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traditional Model - Epoch 47: Train Loss = 0.2470, Train Acc = 91.38%, Test Loss = 0.4238, Test Acc = 86.89%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [48]: 100%|██████████| 391/391 [00:08<00:00, 47.74it/s, acc=91.3, loss=0.277]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traditional Model - Epoch 48: Train Loss = 0.2437, Train Acc = 91.30%, Test Loss = 0.4646, Test Acc = 85.92%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [49]: 100%|██████████| 391/391 [00:08<00:00, 47.38it/s, acc=91.5, loss=0.325]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traditional Model - Epoch 49: Train Loss = 0.2431, Train Acc = 91.46%, Test Loss = 0.4319, Test Acc = 86.56%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [50]: 100%|██████████| 391/391 [00:08<00:00, 47.00it/s, acc=91.7, loss=0.262]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traditional Model - Epoch 50: Train Loss = 0.2373, Train Acc = 91.68%, Test Loss = 0.4217, Test Acc = 86.91%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [51]: 100%|██████████| 391/391 [00:08<00:00, 47.82it/s, acc=91.5, loss=0.267] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traditional Model - Epoch 51: Train Loss = 0.2405, Train Acc = 91.53%, Test Loss = 0.4038, Test Acc = 87.71%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [52]: 100%|██████████| 391/391 [00:08<00:00, 46.60it/s, acc=91.6, loss=0.159]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traditional Model - Epoch 52: Train Loss = 0.2353, Train Acc = 91.60%, Test Loss = 0.4135, Test Acc = 87.54%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [53]: 100%|██████████| 391/391 [00:08<00:00, 48.68it/s, acc=91.7, loss=0.206]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traditional Model - Epoch 53: Train Loss = 0.2308, Train Acc = 91.73%, Test Loss = 0.4259, Test Acc = 87.71%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [54]: 100%|██████████| 391/391 [00:08<00:00, 44.84it/s, acc=91.7, loss=0.235] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traditional Model - Epoch 54: Train Loss = 0.2316, Train Acc = 91.71%, Test Loss = 0.4116, Test Acc = 87.41%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [55]: 100%|██████████| 391/391 [00:08<00:00, 47.61it/s, acc=91.8, loss=0.213]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traditional Model - Epoch 55: Train Loss = 0.2317, Train Acc = 91.77%, Test Loss = 0.4124, Test Acc = 87.58%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [56]: 100%|██████████| 391/391 [00:08<00:00, 46.28it/s, acc=92.1, loss=0.248]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traditional Model - Epoch 56: Train Loss = 0.2270, Train Acc = 92.07%, Test Loss = 0.4456, Test Acc = 87.08%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [57]: 100%|██████████| 391/391 [00:08<00:00, 47.70it/s, acc=92.1, loss=0.145]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traditional Model - Epoch 57: Train Loss = 0.2249, Train Acc = 92.11%, Test Loss = 0.4224, Test Acc = 87.36%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [58]: 100%|██████████| 391/391 [00:08<00:00, 48.64it/s, acc=92.2, loss=0.277] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traditional Model - Epoch 58: Train Loss = 0.2200, Train Acc = 92.25%, Test Loss = 0.4526, Test Acc = 87.01%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [59]: 100%|██████████| 391/391 [00:08<00:00, 47.08it/s, acc=92.2, loss=0.169] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traditional Model - Epoch 59: Train Loss = 0.2180, Train Acc = 92.23%, Test Loss = 0.4844, Test Acc = 86.14%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [60]: 100%|██████████| 391/391 [00:08<00:00, 46.33it/s, acc=92.2, loss=0.26]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traditional Model - Epoch 60: Train Loss = 0.2205, Train Acc = 92.18%, Test Loss = 0.4076, Test Acc = 87.86%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [61]: 100%|██████████| 391/391 [00:08<00:00, 43.80it/s, acc=92.5, loss=0.358] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traditional Model - Epoch 61: Train Loss = 0.2095, Train Acc = 92.49%, Test Loss = 0.4180, Test Acc = 87.62%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [62]: 100%|██████████| 391/391 [00:08<00:00, 47.58it/s, acc=92.4, loss=0.134] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traditional Model - Epoch 62: Train Loss = 0.2128, Train Acc = 92.42%, Test Loss = 0.3977, Test Acc = 88.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [63]: 100%|██████████| 391/391 [00:08<00:00, 45.02it/s, acc=92.6, loss=0.265] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traditional Model - Epoch 63: Train Loss = 0.2109, Train Acc = 92.61%, Test Loss = 0.4164, Test Acc = 87.80%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [64]: 100%|██████████| 391/391 [00:08<00:00, 47.28it/s, acc=92.6, loss=0.203] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traditional Model - Epoch 64: Train Loss = 0.2075, Train Acc = 92.55%, Test Loss = 0.4796, Test Acc = 86.19%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [65]: 100%|██████████| 391/391 [00:08<00:00, 45.63it/s, acc=92.6, loss=0.164] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traditional Model - Epoch 65: Train Loss = 0.2080, Train Acc = 92.62%, Test Loss = 0.4292, Test Acc = 87.42%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [66]: 100%|██████████| 391/391 [00:08<00:00, 46.86it/s, acc=92.8, loss=0.213] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traditional Model - Epoch 66: Train Loss = 0.2039, Train Acc = 92.81%, Test Loss = 0.4463, Test Acc = 87.36%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [67]: 100%|██████████| 391/391 [00:08<00:00, 46.21it/s, acc=92.7, loss=0.164] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traditional Model - Epoch 67: Train Loss = 0.2046, Train Acc = 92.74%, Test Loss = 0.4476, Test Acc = 86.93%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [68]: 100%|██████████| 391/391 [00:08<00:00, 45.57it/s, acc=92.8, loss=0.253] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traditional Model - Epoch 68: Train Loss = 0.2024, Train Acc = 92.83%, Test Loss = 0.4520, Test Acc = 86.68%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [69]: 100%|██████████| 391/391 [00:08<00:00, 45.98it/s, acc=92.9, loss=0.252] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traditional Model - Epoch 69: Train Loss = 0.1998, Train Acc = 92.89%, Test Loss = 0.4203, Test Acc = 87.89%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [70]: 100%|██████████| 391/391 [00:08<00:00, 47.21it/s, acc=92.9, loss=0.168] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traditional Model - Epoch 70: Train Loss = 0.2001, Train Acc = 92.93%, Test Loss = 0.4313, Test Acc = 87.64%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [71]: 100%|██████████| 391/391 [00:08<00:00, 47.75it/s, acc=93, loss=0.282]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traditional Model - Epoch 71: Train Loss = 0.1973, Train Acc = 92.96%, Test Loss = 0.4038, Test Acc = 88.33%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [72]: 100%|██████████| 391/391 [00:08<00:00, 47.63it/s, acc=93, loss=0.144]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traditional Model - Epoch 72: Train Loss = 0.1975, Train Acc = 93.04%, Test Loss = 0.4405, Test Acc = 87.41%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [73]: 100%|██████████| 391/391 [00:08<00:00, 46.88it/s, acc=93.1, loss=0.378] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traditional Model - Epoch 73: Train Loss = 0.1943, Train Acc = 93.14%, Test Loss = 0.4793, Test Acc = 86.57%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [74]: 100%|██████████| 391/391 [00:08<00:00, 48.46it/s, acc=93.2, loss=0.11]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traditional Model - Epoch 74: Train Loss = 0.1914, Train Acc = 93.21%, Test Loss = 0.4416, Test Acc = 87.66%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [75]: 100%|██████████| 391/391 [00:08<00:00, 47.58it/s, acc=93.3, loss=0.113] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traditional Model - Epoch 75: Train Loss = 0.1911, Train Acc = 93.31%, Test Loss = 0.4348, Test Acc = 87.79%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [76]: 100%|██████████| 391/391 [00:08<00:00, 47.07it/s, acc=93.2, loss=0.252] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traditional Model - Epoch 76: Train Loss = 0.1912, Train Acc = 93.18%, Test Loss = 0.4568, Test Acc = 87.46%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [77]: 100%|██████████| 391/391 [00:08<00:00, 47.18it/s, acc=93.3, loss=0.231] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traditional Model - Epoch 77: Train Loss = 0.1849, Train Acc = 93.34%, Test Loss = 0.4165, Test Acc = 87.73%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [78]: 100%|██████████| 391/391 [00:08<00:00, 47.60it/s, acc=93.3, loss=0.36]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traditional Model - Epoch 78: Train Loss = 0.1867, Train Acc = 93.29%, Test Loss = 0.4177, Test Acc = 87.85%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [79]: 100%|██████████| 391/391 [00:08<00:00, 46.69it/s, acc=93.2, loss=0.122] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traditional Model - Epoch 79: Train Loss = 0.1900, Train Acc = 93.22%, Test Loss = 0.4226, Test Acc = 87.85%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [80]: 100%|██████████| 391/391 [00:08<00:00, 46.60it/s, acc=93.4, loss=0.0872]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traditional Model - Epoch 80: Train Loss = 0.1859, Train Acc = 93.39%, Test Loss = 0.4439, Test Acc = 87.60%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [81]: 100%|██████████| 391/391 [00:08<00:00, 46.44it/s, acc=93.6, loss=0.188] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traditional Model - Epoch 81: Train Loss = 0.1819, Train Acc = 93.56%, Test Loss = 0.4586, Test Acc = 87.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [82]: 100%|██████████| 391/391 [00:08<00:00, 45.35it/s, acc=93.5, loss=0.263] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traditional Model - Epoch 82: Train Loss = 0.1817, Train Acc = 93.47%, Test Loss = 0.4477, Test Acc = 86.82%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [83]: 100%|██████████| 391/391 [00:08<00:00, 47.94it/s, acc=93.5, loss=0.125] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traditional Model - Epoch 83: Train Loss = 0.1779, Train Acc = 93.52%, Test Loss = 0.4222, Test Acc = 87.70%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [84]: 100%|██████████| 391/391 [00:08<00:00, 48.33it/s, acc=93.7, loss=0.345] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traditional Model - Epoch 84: Train Loss = 0.1775, Train Acc = 93.65%, Test Loss = 0.4286, Test Acc = 88.32%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [85]: 100%|██████████| 391/391 [00:08<00:00, 47.55it/s, acc=93.7, loss=0.133] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traditional Model - Epoch 85: Train Loss = 0.1767, Train Acc = 93.74%, Test Loss = 0.4383, Test Acc = 87.74%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [86]: 100%|██████████| 391/391 [00:08<00:00, 47.44it/s, acc=93.8, loss=0.151] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traditional Model - Epoch 86: Train Loss = 0.1744, Train Acc = 93.75%, Test Loss = 0.4253, Test Acc = 88.03%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [87]: 100%|██████████| 391/391 [00:08<00:00, 47.94it/s, acc=93.8, loss=0.138] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traditional Model - Epoch 87: Train Loss = 0.1711, Train Acc = 93.83%, Test Loss = 0.4588, Test Acc = 87.42%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [88]: 100%|██████████| 391/391 [00:08<00:00, 47.86it/s, acc=93.7, loss=0.198] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traditional Model - Epoch 88: Train Loss = 0.1752, Train Acc = 93.65%, Test Loss = 0.4408, Test Acc = 87.86%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [89]: 100%|██████████| 391/391 [00:08<00:00, 47.92it/s, acc=93.9, loss=0.232] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traditional Model - Epoch 89: Train Loss = 0.1704, Train Acc = 93.86%, Test Loss = 0.4500, Test Acc = 87.95%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [90]: 100%|██████████| 391/391 [00:08<00:00, 47.99it/s, acc=94, loss=0.256]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traditional Model - Epoch 90: Train Loss = 0.1710, Train Acc = 94.00%, Test Loss = 0.4493, Test Acc = 88.04%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [91]: 100%|██████████| 391/391 [00:08<00:00, 47.96it/s, acc=93.9, loss=0.184] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traditional Model - Epoch 91: Train Loss = 0.1695, Train Acc = 93.92%, Test Loss = 0.4416, Test Acc = 87.73%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [92]: 100%|██████████| 391/391 [00:08<00:00, 47.43it/s, acc=94, loss=0.176]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traditional Model - Epoch 92: Train Loss = 0.1680, Train Acc = 94.04%, Test Loss = 0.4414, Test Acc = 87.88%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [93]: 100%|██████████| 391/391 [00:08<00:00, 48.62it/s, acc=94, loss=0.269]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traditional Model - Epoch 93: Train Loss = 0.1650, Train Acc = 94.04%, Test Loss = 0.4863, Test Acc = 87.31%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [94]: 100%|██████████| 391/391 [00:08<00:00, 47.60it/s, acc=94.1, loss=0.0872]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traditional Model - Epoch 94: Train Loss = 0.1631, Train Acc = 94.11%, Test Loss = 0.4235, Test Acc = 88.10%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [95]: 100%|██████████| 391/391 [00:08<00:00, 47.63it/s, acc=94.2, loss=0.11]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traditional Model - Epoch 95: Train Loss = 0.1622, Train Acc = 94.15%, Test Loss = 0.4308, Test Acc = 88.40%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [96]: 100%|██████████| 391/391 [00:08<00:00, 46.28it/s, acc=94.2, loss=0.203] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traditional Model - Epoch 96: Train Loss = 0.1629, Train Acc = 94.16%, Test Loss = 0.4461, Test Acc = 87.75%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [97]: 100%|██████████| 391/391 [00:08<00:00, 47.75it/s, acc=94.2, loss=0.168] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traditional Model - Epoch 97: Train Loss = 0.1602, Train Acc = 94.24%, Test Loss = 0.4413, Test Acc = 88.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [98]: 100%|██████████| 391/391 [00:08<00:00, 47.95it/s, acc=94.3, loss=0.272] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traditional Model - Epoch 98: Train Loss = 0.1604, Train Acc = 94.25%, Test Loss = 0.4490, Test Acc = 88.02%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [99]: 100%|██████████| 391/391 [00:08<00:00, 47.73it/s, acc=94.2, loss=0.2]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traditional Model - Epoch 99: Train Loss = 0.1632, Train Acc = 94.21%, Test Loss = 0.4399, Test Acc = 88.09%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [100]: 100%|██████████| 391/391 [00:08<00:00, 48.21it/s, acc=94.2, loss=0.18]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traditional Model - Epoch 100: Train Loss = 0.1605, Train Acc = 94.23%, Test Loss = 0.4558, Test Acc = 87.57%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "num_epochs = 100  \n",
    "\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# --- Train Depth-wise Separable Convolution Model ---\n",
    "use_depthwise = True\n",
    "model_depth = DenseNetDS(growth_rate=12, num_init_features=32, block_layers=[4, 4, 4, 4],\n",
    "                         num_classes=10, use_depthwise=use_depthwise, drop_rate=0.0)\n",
    "model_depth = model_depth.to(device)\n",
    "optimizer_depth = optim.Adam(model_depth.parameters(), lr=0.001)\n",
    "print(\"\\nDepth-wise Separable Convolution Model:\")\n",
    "print(\"Number of trainable parameters:\", count_parameters(model_depth))\n",
    "\n",
    "depth_train_losses, depth_train_accs, depth_test_losses, depth_test_accs, depth_best_metrics = \\\n",
    "    train_and_evaluate(model_depth, device, train_loader, test_loader, criterion, optimizer_depth, num_epochs,\n",
    "                       model_name=\"Depth-wise Model\")\n",
    "\n",
    "# --- Train Traditional Convolution Model ---\n",
    "use_depthwise = False\n",
    "model_trad = DenseNetDS(growth_rate=12, num_init_features=32, block_layers=[4, 4, 4, 4],\n",
    "                        num_classes=10, use_depthwise=use_depthwise, drop_rate=0.0)\n",
    "model_trad = model_trad.to(device)\n",
    "optimizer_trad = optim.Adam(model_trad.parameters(), lr=0.001)\n",
    "print(\"\\nTraditional Convolution Model:\")\n",
    "print(\"Number of trainable parameters:\", count_parameters(model_trad))\n",
    "\n",
    "trad_train_losses, trad_train_accs, trad_test_losses, trad_test_accs, trad_best_metrics = \\\n",
    "    train_and_evaluate(model_trad, device, train_loader, test_loader, criterion, optimizer_trad, num_epochs,\n",
    "                       model_name=\"Traditional Model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "FJR0WMEuSNmx"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Comparison of Final Models ===\n",
      "\n",
      "Depth-wise Separable Convolution Model:\n",
      " - Best Test Loss: 0.4405\n",
      " - Best Test Accuracy: 85.98%\n",
      " - Accuracy: 85.98%\n",
      " - Precision: 0.8618\n",
      " - Recall: 0.8598\n",
      " - F1 Score: 0.8602\n",
      " - Parameters: 34613\n",
      " - Inference time (single forward pass): 4.0364 ms\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8549    0.8780    0.8663      1000\n",
      "           1     0.9582    0.8950    0.9255      1000\n",
      "           2     0.8100    0.8230    0.8165      1000\n",
      "           3     0.7289    0.7500    0.7393      1000\n",
      "           4     0.8104    0.8850    0.8461      1000\n",
      "           5     0.8222    0.7860    0.8037      1000\n",
      "           6     0.9237    0.8590    0.8902      1000\n",
      "           7     0.9065    0.8630    0.8842      1000\n",
      "           8     0.9244    0.9170    0.9207      1000\n",
      "           9     0.8787    0.9420    0.9093      1000\n",
      "\n",
      "    accuracy                         0.8598     10000\n",
      "   macro avg     0.8618    0.8598    0.8602     10000\n",
      "weighted avg     0.8618    0.8598    0.8602     10000\n",
      "\n",
      "\n",
      "Traditional Convolution Model:\n",
      " - Best Test Loss: 0.4308\n",
      " - Best Test Accuracy: 88.40%\n",
      " - Accuracy: 88.40%\n",
      " - Precision: 0.8846\n",
      " - Recall: 0.8840\n",
      " - F1 Score: 0.8835\n",
      " - Parameters: 116786\n",
      " - Inference time (single forward pass): 3.2048 ms\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8476    0.9180    0.8814      1000\n",
      "           1     0.9697    0.9280    0.9484      1000\n",
      "           2     0.8684    0.8450    0.8566      1000\n",
      "           3     0.8252    0.7270    0.7730      1000\n",
      "           4     0.8921    0.8760    0.8840      1000\n",
      "           5     0.8200    0.8430    0.8314      1000\n",
      "           6     0.8996    0.9230    0.9112      1000\n",
      "           7     0.8510    0.9370    0.8920      1000\n",
      "           8     0.9417    0.9210    0.9312      1000\n",
      "           9     0.9304    0.9220    0.9262      1000\n",
      "\n",
      "    accuracy                         0.8840     10000\n",
      "   macro avg     0.8846    0.8840    0.8835     10000\n",
      "weighted avg     0.8846    0.8840    0.8835     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def get_model_stats(model, device):\n",
    "    num_params = count_parameters(model)\n",
    "    dummy_input = torch.randn(1, 3, 32, 32).to(device)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        start = time.time()\n",
    "        _ = model(dummy_input)\n",
    "        end = time.time()\n",
    "    inference_time = end - start\n",
    "    return num_params, inference_time\n",
    "\n",
    "# Retrieve best metrics from training (from the epoch with highest test accuracy)\n",
    "depth_test_loss, depth_test_acc, depth_targets, depth_preds = depth_best_metrics\n",
    "trad_test_loss, trad_test_acc, trad_targets, trad_preds = trad_best_metrics\n",
    "\n",
    "# Compute detailed metrics\n",
    "depth_accuracy, depth_precision, depth_recall, depth_f1, depth_report = compute_metrics(depth_targets, depth_preds)\n",
    "trad_accuracy, trad_precision, trad_recall, trad_f1, trad_report = compute_metrics(trad_targets, trad_preds)\n",
    "\n",
    "# Get parameter counts and inference times\n",
    "num_params_depth, time_depth = get_model_stats(model_depth, device)\n",
    "num_params_trad, time_trad = get_model_stats(model_trad, device)\n",
    "\n",
    "print(\"\\n=== Comparison of Final Models ===\\n\")\n",
    "print(\"Depth-wise Separable Convolution Model:\")\n",
    "print(f\" - Best Test Loss: {depth_test_loss:.4f}\")\n",
    "print(f\" - Best Test Accuracy: {depth_test_acc:.2f}%\")\n",
    "print(f\" - Accuracy: {depth_accuracy * 100:.2f}%\")\n",
    "print(f\" - Precision: {depth_precision:.4f}\")\n",
    "print(f\" - Recall: {depth_recall:.4f}\")\n",
    "print(f\" - F1 Score: {depth_f1:.4f}\")\n",
    "print(f\" - Parameters: {num_params_depth}\")\n",
    "print(f\" - Inference time (single forward pass): {time_depth * 1000:.4f} ms\")\n",
    "print(\"\\nClassification Report:\\n\", depth_report)\n",
    "\n",
    "print(\"\\nTraditional Convolution Model:\")\n",
    "print(f\" - Best Test Loss: {trad_test_loss:.4f}\")\n",
    "print(f\" - Best Test Accuracy: {trad_test_acc:.2f}%\")\n",
    "print(f\" - Accuracy: {trad_accuracy * 100:.2f}%\")\n",
    "print(f\" - Precision: {trad_precision:.4f}\")\n",
    "print(f\" - Recall: {trad_recall:.4f}\")\n",
    "print(f\" - F1 Score: {trad_f1:.4f}\")\n",
    "print(f\" - Parameters: {num_params_trad}\")\n",
    "print(f\" - Inference time (single forward pass): {time_trad * 1000:.4f} ms\")\n",
    "print(\"\\nClassification Report:\\n\", trad_report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x400 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "model = model_depth  \n",
    "model.eval()  \n",
    "\n",
    "# Get a batch of test images\n",
    "dataiter = iter(test_loader)\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "# Move images to the device\n",
    "images = images.to(device)\n",
    "\n",
    "# Get predictions from the model\n",
    "with torch.no_grad():\n",
    "    outputs = model(images)\n",
    "    _, predicted = outputs.max(1)\n",
    "\n",
    "# Move predicted labels and true labels to CPU and convert to numpy arrays\n",
    "predicted = predicted.cpu().numpy()\n",
    "labels = labels.cpu().numpy()\n",
    "\n",
    "# Get the class names from the dataset\n",
    "classes = train_dataset.classes\n",
    "\n",
    "# Define how many images you want to display\n",
    "num_images = 5  \n",
    "\n",
    "# Create a figure with subplots for each image\n",
    "fig, axes = plt.subplots(1, num_images, figsize=(15, 4))\n",
    "for i in range(num_images):\n",
    "    # Unnormalize the image to display in its natural colors\n",
    "    img = images[i].cpu()  # Get image from GPU and move to CPU\n",
    "    npimg = img.numpy().transpose((1, 2, 0))\n",
    "    mean = np.array([0.4914, 0.4822, 0.4465])\n",
    "    std = np.array([0.247, 0.243, 0.261])\n",
    "    npimg = std * npimg + mean\n",
    "    npimg = np.clip(npimg, 0, 1)\n",
    "    \n",
    "    # Display the image\n",
    "    axes[i].imshow(npimg)\n",
    "    axes[i].axis('off')\n",
    "    \n",
    "    # Set the title with predicted and actual label\n",
    "    axes[i].set_title(f\"Pred: {classes[predicted[i]]}\\nActual: {classes[labels[i]]}\", fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
